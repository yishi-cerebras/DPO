{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexv/envs/dpo/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, TrainingArguments, pipeline\n",
    "from trl import DPOTrainer\n",
    "from trl.trainer.utils import pad_to_length\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.dpo import get_hh, get_shp\n",
    "import json\n",
    "import types\n",
    "from fuzzywuzzy import fuzz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "MAX_PROMPT_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_dropout(model: torch.nn.Module):\n",
    "    \"\"\"Disable dropout in a model.\"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Dropout):\n",
    "            module.p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98e5b23873a4abf8803967d8ba5fd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexv/envs/dpo/lib/python3.8/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "/home/alexv/envs/dpo/lib/python3.8/site-packages/peft/tuners/lora.py:464: UserWarning: fan_in_fan_out is set to True but the target module is `torch.nn.Linear`. Setting fan_in_fan_out to False.\n",
      "  warnings.warn(\n",
      "Found cached dataset json (/home/alexv/.cache/huggingface/datasets/stanfordnlp___json/stanfordnlp--SHP-dfa8049ac4fac4f6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "Processing SHP: 100%|██████████| 18409/18409 [00:01<00:00, 11836.72it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = AutoModelForCausalLM.from_pretrained('/data/avishnevskiy/experiments/dpo_btlm_shp-20231029-084512/LATEST')\n",
    "# disable_dropout(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained('cerebras/btlm-3b-8k-base')\n",
    "\n",
    "# state_dict = torch.load('../authors_pythia_model.pt')\n",
    "# model.load_state_dict(state_dict['policy'])\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eval_dataset = get_shp(\"test\", sanity_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.028e+03, 3.910e+02, 7.000e+01, 1.500e+01, 1.000e+00, 1.000e+01,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00]),\n",
       " array([  15. ,  426.2,  837.4, 1248.6, 1659.8, 2071. , 2482.2, 2893.4,\n",
       "        3304.6, 3715.8, 4127. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = []\n",
    "for d in eval_dataset:\n",
    "    lens.append(len(tokenizer.tokenize(d['prompt'])))\n",
    "\n",
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_samples(self, model, batch, temperature = 1):\n",
    "        \"\"\"Generate samples from the model and reference model for the given batch of inputs.\"\"\"\n",
    "\n",
    "        policy_output = model.generate(\n",
    "            batch[\"prompt_input_ids\"],\n",
    "            attention_mask=batch[\"prompt_attention_mask\"],\n",
    "            max_length=MAX_LENGTH,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        # if self.ref_model is None:\n",
    "        #     with self.accelerator.unwrap_model(self.model).disable_adapter():\n",
    "        #         reference_output = self.model.generate(\n",
    "        #             batch[\"prompt_input_ids\"],\n",
    "        #             attention_mask=batch[\"prompt_attention_mask\"],\n",
    "        #             max_length=MAX_LENGTH,\n",
    "        #             do_sample=True,\n",
    "        #             pad_token_id=self.tokenizer.pad_token_id,\n",
    "        #             temperature=temperature\n",
    "        #         )\n",
    "        # else:\n",
    "        #     reference_output = self.ref_model.generate(\n",
    "        #         batch[\"prompt_input_ids\"],\n",
    "        #         attention_mask=batch[\"prompt_attention_mask\"],\n",
    "        #         max_length=MAX_LENGTH,\n",
    "        #         do_sample=True,\n",
    "        #         pad_token_id=self.tokenizer.pad_token_id,\n",
    "        #         temperature=temperature\n",
    "        #     )\n",
    "\n",
    "        policy_output = pad_to_length(policy_output, MAX_LENGTH, self.tokenizer.pad_token_id)\n",
    "        policy_output_decoded = self.tokenizer.batch_decode(policy_output, skip_special_tokens=True)\n",
    "\n",
    "        # reference_output = pad_to_length(reference_output, MAX_LENGTH, self.tokenizer.pad_token_id)\n",
    "        # reference_output_decoded = self.tokenizer.batch_decode(reference_output, skip_special_tokens=True)\n",
    "\n",
    "        return policy_output_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy=\"steps\",\n",
    "    do_eval=True,\n",
    "    save_steps=0.2,\n",
    "    output_dir='.',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    save_total_limit=2,\n",
    "    report_to=None,\n",
    "    )\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    model,\n",
    "    args = training_args,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH,\n",
    "    max_prompt_length=MAX_PROMPT_LENGTH,\n",
    ")\n",
    "trainer.get_batch_samples = types.MethodType( get_batch_samples, trainer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../generations/btlm_beta0.1_shp-temp1.json', 'r') as f:\n",
    "    prev_generations = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: How do you cope that you won't deliver a good thesis due to the pandemic? I will finish my PhD next year, but this week I entered the existencial crisis of a PhD: my thesis will not be good. I receive a scholarship from my government to develop my project, which I received after proposing three main objectives, two of them a bit risky but were mangeable - before covid hit. Since the pandemic began, everything I do came to a complete standstill, as I have to work on the laboratory, which was closed for almost a full year. I have a salary until July of next year, but I don't know what I will do until then or even after.  My country (brazil) is in the middile of a 3rd wave, with a 4th wave incoming. My state's healthcare system has already collapsed. Me and the other laboratory members have, since past month, made an agenda where we have no more than 2 people at the same time (so everyone has exactly one day in the week to do their work), but we all know that if we were to catch covid, it's stay at home and hope you don't die, because there is no more oxygen, hospital beds, the medicines used are slowly ending as well, and no vaccination in sight for us (in the brightest scenario, late november to mid december)  My first objective has been completely cancelled, impossible to do until late 2022, because the facility has closed. The second one involves an experimental technique that we still haven't been able to finish developing (people involved have left the city/state due to covid, facilities are still not open, purchase of new chemical reagents has been slow because everything is out of stock). The third objective requires me travelling to another side of the country (about 10h by bus) and spend some weeks working in another laboratory, something that not only is not recommended to due in the midst of our health crisis, but also I do not feel comfortable in doing as my immune system sucks and I'm very prone to getting sick, which is why I have been in quarantine for as much as I can, only leaving home for the essentials (and more recently to work).  So there we have it. I don't have anything to continue with my original plans and objectives, I don't know if I have a story to tell with all the incomplete and broken data that I have, and I'm scared shitless of having to do a complete 180º on my project which, if it's not accepted by my funding agency, they have the right to cancel my scholarship and demand that I pay them back everything that they have given me, which I mostly ceratinly cannot do. Besides changing everything when I have about 14 to 15 months left on my PhD (after this time I will be without a scholarship, and I cannot survive here without it due to money reasons), the only alternative I see is to lengthen this PhD until god knows when, when I'm finally able to complete all three objectives. I am absolutely lost, and later today I also have a meeting with my advisor because he wants to talk about my project...\n",
      "\n",
      "Assistant:\n",
      " in the midst of our health crisis, but also I do not feel comfortable in doing as my immune system sucks and I'm very prone to getting sick, which is why I have been in quarantine for as much as I can, only leaving home for the essentials (and more recently to work).  So there we have it. I don't have anything to continue with my original plans and objectives, I don't know if I have a story to tell with all the incomplete and broken data that I have, and I'm scared shitless of having to do a complete 180º on my project which, if it's not accepted by my funding agency, they have the right to cancel my scholarship and demand that I pay them back everything that they have given me, which I mostly ceratinly cannot do. Besides changing everything when I have about 14 to 15 months left on my PhD (after this time I will be without a scholarship, and I cannot survive here without it due to money reasons), the only alternative I see is to lengthen this PhD until god knows when, when I'm finally able to complete all three objectives. I am absolutely lost, and later today I also have a meeting with my advisor because he wants to talk about my project...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we use the same dataset as before\n",
    "def check_dataset(dataset = 'hh'):\n",
    "    if dataset == 'hh':\n",
    "        with open('../generations/btlm_without_lora_generations-temp1.json', 'r') as f:\n",
    "            prev_generations = json.loads(f.read())\n",
    "    elif dataset == 'shp':\n",
    "        with open('../generations/btlm_beta0.1_shp-temp1.json', 'r') as f:\n",
    "            prev_generations = json.loads(f.read())\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    for i, b in enumerate(trainer.get_eval_dataloader()):\n",
    "        if i == 256:\n",
    "            break\n",
    "        \n",
    "        prev_gen = prev_generations[i]['prompt']\n",
    "        if isinstance(prev_gen, list):\n",
    "            prev_gen = prev_gen[0]\n",
    "\n",
    "        if fuzz.ratio(b['prompt'][0],  prev_gen) < 95:\n",
    "            print(b['prompt'][0])\n",
    "            print(prev_gen)\n",
    "            return False   \n",
    "    return True\n",
    "\n",
    "check_dataset('shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [12:23,  3.32s/it]"
     ]
    }
   ],
   "source": [
    "generations = []\n",
    "eval_loader = trainer.get_eval_dataloader()\n",
    "for i, b in tqdm(enumerate(eval_loader)):\n",
    "    if i >= 256:\n",
    "        break\n",
    "    \n",
    "    policy = trainer.get_batch_samples(model, b, 1)\n",
    "    assistant_word = '\\n\\nAssistant:'\n",
    "    resp_indx = policy[0].rfind(assistant_word)\n",
    "    prompt = b['prompt'][0][:resp_indx]\n",
    "    policy_response = policy[0][resp_indx+len(assistant_word):].strip()\n",
    "    # reference_response = reference[0][resp_indx+len(assistant_word):].strip()\n",
    "    chosen_response = b['chosen'][0][resp_indx+len(assistant_word):].strip()\n",
    "\n",
    "    generations.append({'prompt': prompt, 'chosen_response': chosen_response, 'policy_response': policy_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../generations/btlm_beta0.5_shp-temp1.json', 'w') as json_file:\n",
    "    json.dump(generations, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(eval_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../generations/same_anthropic-temp1.json', 'r') as f:\n",
    "    same_hp_samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8552it [36:21,  3.92it/s]\n"
     ]
    }
   ],
   "source": [
    "idxs = []\n",
    "for i, batch in tqdm(enumerate(eval_loader)):\n",
    "    for sample in same_hp_samples:\n",
    "        if fuzz.ratio(batch['prompt'][0], sample['prompt']) > 95:\n",
    "            idxs.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHuman: I\\'d love to learn more about the artist Mary Cassatt, specifically \"The Child\\'s Bath\", although biography information also helps.\\n\\nAssistant:'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHuman: How can I tell the radio announcer to fuck off live on air?\\n\\nAssistant: I’m not sure I understand the question.\\n\\nHuman: I want to make a jerk out of the live announcer on air and tell him to fuck off.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
